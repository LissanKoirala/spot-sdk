
<html>
  <head>
    <title>Spot SDK</title>
    <link rel="stylesheet" type="text/css" href="./../../css/markdown.css"/>
  </head>
  <body class="markdown-body">
  
<h1><a href="../../../index.html">Spot SDK</a> &gt; <a href="../index.html">Concepts</a> &gt; <a href="index.html">Autonomy</a> &gt; <br> GraphNav Map Structure</h1>
<p>GraphNav maps consist of waypoints and edges between the waypoints. A waypoint consists of a reference frame, a name, a unique ID, annotations, and sensor data. Each waypoint contains a snapshot, which bundles the various sensor data into one unit.</p>
<ul>
<li>Waypoint data includes feature clouds, AprilTag detections, imagery, terrain maps, etc.</li>
<li>Edges consist of a directed edge from one waypoint to another and a transform that estimates the relationship in 3D space between the two waypoints.</li>
</ul>
<h2>view_map.py example</h2>
<p>Use the <a href="../../../python/examples/graph_nav_view_map/view_map.py">view_map.py</a> Python example in the Spot SDK to view maps recorded using Autowalk on the controller tablet, or using the Spot GraphNav service.</p>
<p>Point cloud data is captured at each waypoint. These data depict features that the robot encountered during the map recording process. The point clouds are colored by height, where blue is higher and red is lower.</p>
<p>The viewer also shows fiducials that were detected during the map recording process. Fiducials are shown as blue squares labeled with the fiducial ID. If multiple fiducials with the same ID are displayed near each other, this represents multiple detections taken at different times during recording.</p>
<p>Maps do not have a global coordinate system (like GPS coordinates, for example). Only the relative transformations between waypoints are known.</p>
<h2>Creating waypoints</h2>
<p>Waypoints are created by the robot every two meters during map recording. However, they can be created in areas where the robot’s path has more curvature as it navigates around corners and obstacles.</p>
<p>Call CreateWaypoint at specific locations in order to perform some action in a mission or when you want to explicitly maintain some mapping between a user event and a waypoint ID. Example: creating a waypoint at an inspection point.</p>
<h2>Downloading maps</h2>
<p>Waypoints and edges have associated snapshots that store data the robot uses to compute localization and inform the robot’s locomotion.</p>
<ul>
<li>Waypoint snapshots contain geometry and image data for localization.</li>
<li>Edge snapshots contain only the robot's footstep locations.</li>
<li>Edge annotations contain hints such as 'this edge traverses stairs' which informs the lower level locomotion systems on the robot.</li>
</ul>
<p>The recording process creates waypoints, edges between them, and snapshot data on the robot.</p>
<p>Snapshot data are recorded and cached on the robot. To preserve and reuse a map, it must be downloaded from the robot. Graph data is not cached. Though the cache is large (up to 5GB) and persists across reboots, recording new maps might move waypoints and edges in a recorded map out of the cache. As a rule, we recommend downloading a recorded map at the conclusion of the recording process.</p>
<p>Because graph data is not cached, this data is lost when the robot is rebooted. Downloading snapshot data using DownloadSnapshot may work but should be downloaded before rebooting the robot.</p>
<p>Saving the map for reuse involves two steps:</p>
<ol>
<li>Download the structure of the map by calling the DownloadGraph RPC.</li>
<li>Download snapshot data by calling the DownloadWaypointSnapshot and DownloadEdgeSnapshot RPCs.</li>
</ol>
<p>Two steps are needed because snapshot data is very large. Snapshots are downloaded via a streaming RPC. The request is initiated by specifying which snapshot ID to download and, for waypoint snapshots, whether or not to include full image data in the download. Note that the full image data is not needed for the robot to navigate.</p>
<h2>Download a map from the controller tablet</h2>
<p>To download a map recorded using Autowalk on the tablet, transfer the map to your local machine from the following location on the controller:</p>
<pre><code>Documents/bosdyn/autowalk/your_map.walk
</code></pre>
<p>Attach a USB cable between tablet or computer to transfer files. The map files should have the following directory structure on your local system:</p>
<pre><code>/your_map.walk
    graph
    waypoint_snapshots
    edge_snapshots
</code></pre>
<h2>Uploading maps</h2>
<p>Maps stored on client computers can be uploaded to the robot for reuse in two steps:</p>
<ol>
<li>The map structure is uploaded as a graph to the robot using the UploadGraphRequest RPC.</li>
<li>Snapshot data is uploaded to the robot using the streaming UploadWaypoint/EdgeSnapshot RPCs.</li>
</ol>
<p>See the <a href="../../../python/examples/graph_nav_command_line/graph_nav_command_line.py">graph_nav_command_line.py</a> Python code example for details about uploading edge and waypoint snapshots, and graphs to the robot.</p>
<br>
<p><a href="graphnav_service.html">« Previous</a>  |  <a href="initialization.html">Next »</a></p>

  </body>
</html>
