
<html>
  <head>
    <title>Spot SDK</title>
    <link rel="stylesheet" type="text/css" href="./../../../docs/css/markdown.css"/>
  </head>
  <body class="markdown-body">
  
<h1>Spot Tensorflow Detector</h1>
<p>Spot Tensorflow Detector example collects images from the 5 Spot cameras and performs object detection using Tensorflow. It accepts any Tensorflow model, and it allows the user to specify a subset of detection classes included in the model. It performs this set of operations for a predefined number of iterations, blocking for a predefined amount of time between each iteration. The output of each iteration is a plot of the original 5 images collected from the cameras and another set of those 5 images with boxes around the detections reported by the Tensorflow model.</p>
<p>The program is organized as three sets of Python processes communicating with the Spot robot. The process diagram is shown below. The main process communicates with the Spot robot over GRPC and constanty receives images.These images are pushed into the RAW_IMAGES_QUEUE and read by the Tensorflow processes.Those processes detect objects in the images, draw the bounding boxes around the detections, and push those processed images into the PROCESSED_IMAGES_QUEUE. The Display process then pull images from the PROCESSED_IMAGES_QUEUE and displayes them to the screen.</p>
<p><a target="_blank" rel="noopener noreferrer" href="documentation/process_diagram.png"><img src="documentation/process_diagram.png" alt="Process Diagram" width="250" style="max-width:100%;"></a></p>
<h2>User Guide</h2>
<h3>Installation</h3>
<p>To install this example on Ubunty 18.04, follow these instructions:</p>
<ul>
<li>Install python3: <code>sudo apt-get install python3.6</code></li>
<li>Install pip3: <code>sudo apt-get install python3-pip</code></li>
<li>Install virtualenv: <code>pip3 install virtualenv</code></li>
<li>Change into example directory: <code>cd spot_tensorflow_detector</code></li>
<li>Create virtual environment (one time operation): <code>virtualenv -p {PATH_TO_PYTHON3_EXECUTABLE} venv</code>. The path to the executable is the output of <code>which python3</code> command, usually set to <code>/usr/bin/python3</code>.</li>
<li>Start virtual environment: <code>source venv/bin/activate</code></li>
<li>Install dependencies: <code>python -m pip install -r requirements.txt</code></li>
<li>Run the example using instructions in the next section</li>
<li>To exit the virtual environment, run <code>deactivate</code></li>
</ul>
<h3>Execution</h3>
<p>This example follows the common pattern for expected arguments. It needs the common arguments used to configure the SDK and connect to a Spot:</p>
<ul>
<li>--username</li>
<li>--password</li>
<li>--app-token</li>
<li>hostname passed as the last argument</li>
</ul>
<p>On top of those arguments, it also needs the following arguments:</p>
<ul>
<li>--model-path (required) argument that specifies the path of the Tensorflow model (a file in .pb format)</li>
<li>--detection-classes (optional) argument that specifies a comma-separated list of detection classes to use from the Tensorflow model; not specifying this argument means that all classes in the model will be detected</li>
<li>--detection-threshold (optional) argument that specifies the threshold to use to consider the Tensorflow detections as real detections; defaults to 0.7</li>
<li>--number-tensorflow-processes (optional) argument that specifies the number of Tensorflow processes to start; defaults to 7</li>
<li>--sleep-between-capture (optional) argument that specifies the amount to sleep in seconds between each image capture iteration; defaults to 0.0</li>
<li>--max-processing-delay (optional) argument that specifies max delay in seconds allowed for each image before being processed; images with greater latency will not be processed</li>
<li>--max-display-delay (optional) argument that specifies max delay in seconds allowed for each image before being displayed; images with greater latency will not be displayed</li>
</ul>
<pre><code>python spot_tenserflow_detector.py --username USER --password PASSWORD --model-path &lt;path_to_pb&gt; ROBOT_IP
</code></pre>
<p>The program generates two sets of output:</p>
<ul>
<li>A set of 5 image windows with live images from the five cameras with boxes around the Tensorflow detections.</li>
<li>A command line log in the format:<br><br>
<code>RAW_IMAGES_QUEUE   PROCESSED_IMAGES_QUEUE   Network_Delay   Processing_Delay   Display_Delay   Total_Delay   Display_Skips   Processing_Skips</code><br><br>
The value of all those parameters is updated asynchronously. The parameters are:
<ul>
<li>RAW_IMAGES_QUEUE: The size of the queue holding raw images; main process adds raw images in this queue and the Tensorflow processes get images from this queue</li>
<li>PROCESSED_IMAGES_QUEUE: The size of the queue holding processes images; Tensorflow processes add processed images in this queue and the Display process gets images from this queue</li>
<li>Network_Delay: Delay in seconds between when the image is captured in the robot and the time it is received by this program</li>
<li>Processing_Delay: Amount of time in seconds it takes a Tensorflow processor to process the image</li>
<li>Display_Delay: Amount of time in seconds it takes to show the processed image</li>
<li>Total_Delay: Total delay in seconds between when the image is captured in the robot and the time it is shown on the screen</li>
<li>Display_Skips: Total number of images skipped from being displayed due to latency</li>
<li>Processing_Skips: Total number of images skipped from being processed in each Tensorflow process due to latency</li>
</ul>
</li>
</ul>
<p>The value for RAW_IMAGES_QUEUE increases rapidly in the beginning of the program, but it should decrease back to 0 in a few minutes. Based on the hardware where the program is running, increasing the value passed to the argument <code>--number-tensorflow-processes</code> reduces the size of this queue more quickly. Increasing the value of the argument <code>--sleep-between-capture</code> also reduces the size of this queue, but this option also reduces the real-time visualization of the environment around the Spot robot.</p>
<p>Tensorflow models pre-trained on COCO dataset can be obtained <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="nofollow">here</a>. As an example, use the pb file from the faster_rcnn_inception_v2_coco model with --detection-classes argument set to 1 to detect people in the camera images. The models in that tensorflow github location are not supported on Windows or MacOS.</p>
  </body>
</html>
